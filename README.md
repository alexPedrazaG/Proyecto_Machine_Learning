# üöÄProyecto Machine Learning

## üìå Descripci√≥n
El objetivo de este proyecto es realizar un preprocesamiento de los datos proporcionados, seguido de la implementaci√≥n de un modelo de regresi√≥n lineal y un modelo de regresi√≥n log√≠stica.

## üóÇÔ∏è Estructura del Proyecto
‚îú‚îÄ‚îÄ data

	‚îú‚îÄ‚îÄ raw
	
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_estudiantes.csv # Se encuentra el fichero de an√°lisis proporcionado por la escuela

	‚îú‚îÄ‚îÄ processed
	
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset_estudiantes_clean.csv # Es el resultado de aplicar 01_LimpiezaDatos_EDA.ipynb

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ df_regresion.csv # Es el resultado de aplicar 02_Preproceso.ipynb

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ df_clasificacion.csv # Es el resultado de aplicar 02_Preproceso.ipynb

‚îÇ
‚îú‚îÄ‚îÄ models

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modelo_regresion.pkl # Modelo de regresi√≥n lineal entrenado para predicci√≥n de nota_final

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modelo_clasificacion.pkl # Modelo de Regresi√≥n Log√≠stica entrenado para predicci√≥n de aprobado/suspenso

‚îÇ
‚îú‚îÄ‚îÄ notebooks

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 01_LimpiezaDatos_EDA.ipynb   # Limpieza de datos, an√°lisis exploratorio y detecci√≥n de inconsistencias (EDA)

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 02_Preproceso.ipynb    # Preprocesamiento de variables, codificaci√≥n, escalado y gesti√≥n de outliers 

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 03_Regresion.ipynb    # Construcci√≥n, entrenamiento y evaluaci√≥n del modelo de regresi√≥n para predecir nota_final 

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 04_Clasificacion.ipynb    # Construcci√≥n, entrenamiento y evaluaci√≥n del modelo de clasificaci√≥n para predecir aprobado/suspenso

‚îú‚îÄ‚îÄ README.md # Descripci√≥n del proyecto

## üõ†Ô∏è Instalaci√≥n y Requisitos
En este proyecto es necesario utilizar:

+ Python 3.13.2 (es la versi√≥n que he utilizado para hacer los ejercicios)
+ Librerias: Pandas, Numpy, Matplotlib, Seaborn, KNNImputer, Scikit-learn, Joblib
+ Visual Studio Code

## üéØ Criterios
- An√°lisis exploratorio (EDA).
- Preprocesamiento.
- Entrenamiento y validaci√≥n del modelo de regresi√≥n.
- Entrenamiento y validaci√≥n del modelo de clasificaci√≥n.
- Informe en un archivo README
- Correcta entrega en GitHub

## üìù Dataset
El conjunto de datos 'dataset_estudiantes.csv' trata sobre el rendimiento acad√©mico de estudiantes y tiene las siguientes caracter√≠sticas:

### Columnas del dataset
+ horas_estudio_semanal: N√∫mero de horas de estudio a la semana.
+ nota_anterior: Nota que obtuvo el alumno en la convocatoria anterior.
+ tasa_asistencia: Tasa de asistencia a clase en porcentaje.
+ horas_sueno: Promedio de horas que duerme el alumno al d√≠a.
+ edad: Edad del alumno.
+ nivel_dificultad: Dificultad del alumno para el estudio.
+ tiene_tutor: Indica si el alumno tiene tutor o no.
+ horario_estudio_preferido: Horario de estudio preferido por el alumno.
+ estilo_aprendizaje: Forma de estudio que emplea el alumno.

### Variables objetivo:
+ Regresi√≥n: nota_final (variable continua entre 0 y 100)
+ Clasificaci√≥n: aprobado (variable binaria: 1 si la nota es ‚â• 60, 0 en caso contrario)

## üìä An√°lisis de proyecto
### 1. Introducci√≥n y Preparaci√≥n de los Datos
Se ha llevado a cabo un An√°lisis Exploratorio de Datos (EDA) sobre el rendimiento acad√©mico de 1000 estudiantes, para aplicar un modelo de regresi√≥n lineal y un modelo de regresi√≥n log√≠stica, con el objetivo de predecir, en base a las variables analizadas, su nota final o si aprobar√° o no.

Se ha decidido dividir los distintos pasos en diferentes ficheros para una mejor legibilidad. Partimos del fichero 'dataset_estudiantes.csv', al que se le aplic√≥ una limpieza de datos y se realiz√≥ el an√°lisis exploratorio en '01_LimpiezaDatos_EDA.ipynb', dando como resultado el fichero 'dataset_estudiantes_clean.csv'.
Este √∫ltimo se tomar√° como origen en el fichero '02_Preproceso.ipynb' para realizar el preprocesamiento de los datos y su escalado. Al finalizar se guardar√°n dos DataFrames para su an√°lisis 'df_regresion.csv' y 'df_clasificacion.csv'. En cada uno de ellos implementar√° el modelo de regresi√≥n correspondiente, los ficheros utilizados son: '03_Regresion.ipynb' y '04_Clasificacion.ipynb'

### 2. 01_LimpiezaDatos_EDA

**EDA**  

**Importar librer√≠as**

Importamos las librer√≠as necesarias para hacer nuestro an√°lisis:

##### Manipulaci√≥n de datos
- pandas
- numpy

##### Visualizaci√≥n
- matplotlib.pyplot
- seaborn

##### Normalizaci√≥n de texto
- unicodedata 

##### Imputaci√≥n de datos faltantes
- sklearn.impute(KNNImputer)

Se utiliza la opcion 'display.max_columns' para ver todas columnas del fichero. Se carga el fichero de origen en 'df_raw' y se realiza un 'head' para ver que contiene los datos.

**An√°lisis Exploratorio**  

Se utiliza el atributo 'shape' para saber que el fichero contiene 1000 filas y 11 columnas. Tambi√©n se usa 'info' para tener una informacion general del fichero. Se ve que hay 7 columnas n√∫mericas (5 de ellas tipo float y 2 como int) y 4 categ√≥ricas. Adem√°s que las columnas 'horas_sueno', 'horario_estudio_preferido' y 'estilo_aprendizaje' poseen nulos. 

Se realiza una copia del dataFrame en uno nuevo ('df') para dejar sin modificar el fichero original. 

Se hace un 'round(2)' para las columnas num√©ricas ya que en la vista previa del 'head' se observaban 6 decimales, reduci√©ndolos a 2 para mejorar la legibilidad.

En el siguiente paso, se describen las columnas.


**Verificaci√≥n de duplicados**  

Se usa el atributo 'duplicated' y 'sum' para verificar duplicados; no se detectaron registros duplicados.


**Verificaci√≥n y manejo de nulos**

Se hace un 'isna().sum' para identificar los valores nulos. Como se mencion√≥ antes, existen nulos en tres columnas: 
- 'horas_sueno' (150 nulos)
- 'horario_estudio_preferido' (100 nulos)
- 'estilo_aprendizaje' (50 nulos).


**Identificar variables categ√≥ricas y num√©ricas**

Se indentifican las columnas categ√≥ricas y las num√©ricas para aplicar funciones espec√≠ficas m√°s adelante.

- Columnas num√©ricas: ['horas_estudio_semanal', 'nota_anterior', 'tasa_asistencia', 'horas_sueno', 'edad', 'nota_final', 'aprobado']
- Columnas categ√≥ricas: ['nivel_dificultad', 'tiene_tutor', 'horario_estudio_preferido', 'estilo_aprendizaje']
	   
Para el control de nulos de las columnas 'horario_estudio_preferido' y 'estilo_aprendizaje'(categ√≥ricas), se rellenar√°n con el valor 'Desconocido'
Para 'horas_sueno' (num√©rica), se utiliza KNNImputer, preservando patrones entre variables en lugar de asignar un valor fijo.

Se verifica nuevamente que los nulos han desaparecido y se crea una funci√≥n para eliminar tildes en 'nivel_dificultad' y 'tiene_tutor', evitando problemas futuros.


**Variables num√©ricas**

**Estad√≠sticas descriptivas** 
 
Se realiza un 'describe().T' para mostrar las estad√≠sticas descriptivas de forma legible. No se detecta nada fuera de lo com√∫n.


**Visualizaciones**

Se realiza un 'histplot' para cada variable num√©rica (25 grupos):

*1. Distribuci√≥n de horas_estudio_semanal:*
Distribuci√≥n normal, la mayor parte de estudiantes dedica entre 7 y 14 horas semanales. Destaca un grupo de estudiantes que estudia solo 1 hora.

*2. Distribuci√≥n de nota_anterior:*
Distribuci√≥n normal, concentrada entre 60 y 80 puntos. Destaca un grupo con la nota m√°xima.

*3. Distribuci√≥n de tasa_asistencia:*
La mayor√≠a tiene entre 65% y 85%, destacando un grupo con 100% de asistencia.

*4. Distribuci√≥n de horas_sueno:*
La mayor√≠a duerme entre 6,5 y 8,5 horas. Sorprende que un cuarto de los estudiantes duerma menos de 6,5 horas. Dos grupos extremos duermen 4 y 10 horas.

*5. Distribuci√≥n de edad:*
Distribuci√≥n relativamente uniforme entre 18 y 29 a√±os, con ligera mayor√≠a de 18 a√±os.

*6. Distribuci√≥n de nota_final:*
Distribuci√≥n centrada entre 62% y 80%. M√°s aprobados que suspensos.

*7. Distribuci√≥n de aprobado:*
Mayor n√∫mero de aprobados que suspensos.


**Variables categ√≥ricas**

**Estad√≠sticas descriptivas** 

Se aplica un 'describe().T'. Todas las columnas tienen 1000 registros:

- 'nivel_dificultad', 3 categor√≠as, predominando "Medio" (504 estudiantes)
- 'tiene_tutor', 2 categor√≠as, predominando "No" (597 estudiantes).
- 'horario_estudio_preferido', 4 categor√≠as, predominando "Noche" (344 estudiantes).
- 'estilo_aprendizaje', 5 categor√≠as, predominando "Visual" (363 estudiantes).


**Valores √∫nicos y frecuencias**

Se itera sobre 'cat_cols' para mostrar valores √∫nicos y frecuencia de cada uno.


**Visualizaciones**

Se genera un gr√°fico de barras para cada variable categ√≥rica, ajustando din√°micamente la anchura (m√≠n. 7, m√°x. 25):

*1. Distribuci√≥n de nivel_dificultad:* Predomina "Medio", seguido de "F√°cil" y "Dif√≠cil".

*2. Distribuci√≥n de tiene_tutor:* M√°s estudiantes sin tutor.

*3. Distribuci√≥n de horario_estudio_perfecto:* Predomina "Noche"; hay un grupo de 100 estudiantes con valor "Desconocido".

*4. Distribuci√≥n de estilo_aprendizaje:* Predomina "Visual", seguido de "Auditivo", "Kinest√©sico", "Lectura/Escritura" y "Desconocido" (50 estudiantes).


**Matriz de Correlaci√≥n**

Se aplica la matriz de correlaci√≥n para las variables num√©ricas utilizando el atributo 'corr', mostrando √∫nicamente la parte triangular para evitar duplicados. No hay ninguna correlacion alta o media alta.Hay algunas correlaciones moderadas:
- Entre 'aprobado' y 'nota_final', lo cual tiene sentido: a mayor 'nota_final', m√°s probable es que el estudiante est√© aprobado.
- Entre 'nota_final' y 'horas_estudio_semanal', indicando que a mayor n√∫mero de horas de estudio semanal, mayor suele ser la nota.
- Entre 'nota_final' y 'nota_anterior', lo que sugiere que los alumnos que aprobaron el examen anterior tienen m√°s probabilidades de aprobar el examen final.
- Entre 'horas_estudio_semanal' y 'nota_anterior', siguiendo la misma l√≥gica de la 'nota_final'.

Existen algunas correlaciones bajas entre otras variables y algunas correlaciones negativas, pero son pr√°cticamente nulas.


**Relaciones Cruzadas**


**1. Variable objetivo nota_final**


***Variables num√©ricas***

Se genera un gr√°fico de dispersi√≥n por cada variable num√©rica. En el eje x se encuentra la variable de estudio, en el eje y la variable objetivo 'nota_final'. Adem√°s, se ha incluido la variable 'aprobado' con otro color para visualizar mejor la relaci√≥n entre tres variables.

*1. Horas_estudio_semanal:*
Se observa una gran concentraci√≥n de estudiantes con entre 7 y 14 horas de estudio semanal, como se mencion√≥ anteriormente. Todos los estudiantes que han estudiado m√°s de 16 horas semanales aprobaron. Llama la atenci√≥n que varios estudiantes que estudiaron solo 1 hora semanal tambi√©n aprobaron.

*2. Nota_anterior:*
La mayor√≠a de los estudiantes que aprobaron el examen anterior tambi√©n aprobaron el examen final. Destaca que algunos alumnos que suspendieron (nota inferior a 60) en el examen anterior lograron aprobar el examen final. Tambi√©n hay casos de alumnos que aprobaron el primer examen pero suspendieron el final.
Podemos concluir que si un estudiante no supera el 60% en ambos ex√°menes, no aprueba. En general, m√°s alumnos aprobaron el examen final que el anterior.

*3. Tasa_asistencia:*
La mayor√≠a de los aprobados tienen una asistencia entre 65% y 85%. Todos los alumnos con asistencia del 100% aprobaron. Entre los que menos asistieron, hubo m√°s aprobados que suspensos.

*4. Horas_sueno:*
Los aprobados suelen dormir entre 6,5 y 8,5 horas. Sorprende que algunos estudiantes que duermen solo 4 horas aprobaron, al igual que los que duermen 10 horas.

*5. Edad:*
No se observan patrones destacables; los valores est√°n bastante equilibrados.

*6. Aprobado:*
Para aprobar se requiere superar el 60% de la nota final. Se confirma que hay m√°s aprobados que suspensos.


***Variables categ√≥ricas***

Se crean gr√°ficos de bigotes por cada columna. En el eje x est√° la variable de estudio y en el eje y la variable objetivo. Se agrupan por la variable de estudio y se ordenan seg√∫n la media de la variable objetivo.

*1. Nivel_dificultad:*
Todos los estudiantes tienen 'nota_final' superior al 60%, lo que indica que la mayor√≠a aprueba seg√∫n su categor√≠a. La media m√°s alta se encuentra en los alumnos con nivel de dificultad 'F√°cil'.

*2. Tiene_tutor:*
Los alumnos que tienen tutor presentan una mejor 'nota_final' que los que no lo tienen. Sin embargo, algunos alumnos sin tutor lograron notas m√°s altas que la media de los que s√≠ lo ten√≠an, apareciendo como outliers.

*3. Horario_estudio_preferido:*
Todas las categor√≠as muestran una media de notas similar. Destaca que los alumnos que estudian por la tarde obtuvieron la mejor nota media final. Algunos registros se clasifican como 'desconocido', y ser√≠a recomendable reasignarlos para confirmar si los resultados se mantienen.

*4. Estilo_aprendizaje:*
Resultados similares a los anteriores. El mejor promedio se observa en la categor√≠a 'Lectura/Escritura'.


**2. Variable objetivo aprobado**

Se genera un histograma si las variables son num√©ricas o un countplot si son categ√≥ricas. En el eje x est√° la variable de estudio y en el eje y la variable objetivo.

*1. Horas_estudio_semanal:*
Los estudiantes que dedican menos horas al estudio son los que m√°s suspenden. Algunos casos excepcionales, incluso estudiando 15 horas, suspendieron, pero no es lo habitual. Todos los estudiantes que estudian m√°s de 15 horas aprueban.

*2. Nota_anterior:*
Muchos alumnos que suspendieron el examen anterior lograron aprobar el final. La mayor√≠a de los que suspendieron el examen anterior tambi√©n suspendieron el examen final. Algunos casos excepcionales, como un estudiante con nota m√°xima en el examen anterior, suspendieron el examen final. Los grupos donde la mayor√≠a suspendi√≥ el primer examen tienden a no aprobar el segundo examen.

*3. Tasa_asistencia:*
A mayor asistencia, menor proporci√≥n de suspensos. Se observa un peque√±o repunte de suspensos entre los alumnos con 100% de asistencia. La mayor concentraci√≥n de suspensos se encuentra en tasas de asistencia entre 60-65%.

*4. Horas_sueno:*
Los estudiantes que duermen entre 6,5 y 8 horas son los que m√°s aprueban. Sorprenden algunos casos de estudiantes que duermen 4 horas y aprueban, similar a los que duermen 10 horas. Curiosamente, los estudiantes que duermen alrededor de 7 horas son los que m√°s suspenden.

*5. Edad:*
Los estudiantes de 29 a√±os concentran la mayor cantidad de aprobados y suspensos. El resto de edades est√° bastante equilibrado.

*6. Nivel_dificultad:*
Los estudiantes con nivel de dificultad 'Medio' concentran la mayor√≠a de aprobados y suspensos. Esto refleja que la categor√≠a 'Medio' tiene m√°s alumnos.

*7. Tiene_tutor:*
M√°s aprobados se encuentran entre los alumnos que no tienen tutor. Sin embargo, entre los que s√≠ tienen tutor, la proporci√≥n de suspensos es menor.

*8. Horario_estudio_preferido:*
Los alumnos que estudian por la 'Tarde' y la 'Noche' concentran la mayor√≠a de aprobados y suspensos, siendo ligeramente superior el grupo nocturno. Los de la ma√±ana tambi√©n tienen una buena tasa de aprobados.

*9. Estilo_aprendizaje:*
Destaca que los estudiantes con estilo de aprendizaje 'Visual' tienen un mejor desempe√±o relativo, tanto en aprobados como en suspensos. Es interesante que esta categor√≠a no aparec√≠a en el primer lugar cuando la variable objetivo era 'nota_final'.

*10. Nota_final:*
Los estudiantes que superan el 60% aprueban; los que no, suspenden. Se observa que los estudiantes que obtienen exactamente 60% presentan m√°s suspensos que aprobados, lo que indica que se eval√∫a alguna otra variable para decidir la aprobaci√≥n final.


**An√°lisis de Inconsistencias**

Se a√±adieron reglas para identificar posibles inconsistencias y as√≠ eliminarlas para no afectar el an√°lisis. Se cre√≥ una lista vac√≠a para ir almacenando las inconsistencias detectadas. Las reglas fueron:

1. 'Horas_estudio_semanal' no pod√≠a superar las 60 horas semanales.
2. 'Nota_final' y las 'Nota_anterior' deb√≠an estar entre 0 y 100.
3. 'Hora_sueno' deb√≠a estar entre 0 y 24 horas.
4. 'Edad' deb√≠a estar entre 18 y 100 a√±os.

Al finalizar, la lista de inconsistencias result√≥ vac√≠a, confirmando que no hab√≠a datos fuera de rango.


**Export fichero limpio**

Se exporta el fichero limpio para los siguientes pasos del an√°lisis. Se guarda con el nombre 'dataset_estudiantes_clean.csv' en la ruta ../data/processed/.

### 3. 02_Preproceso

**Importar librer√≠as**  
Importamos las librer√≠as necesarias para hacer nuestro an√°lisis:

###### Manipulaci√≥n de datos
- pandas
- numpy
- math

###### Estad√≠stica y normalizaci√≥n
- scipy.stats (zscore)
- sklearn.preprocessing (MinMaxScaler, OneHotEncoder, OrdinalEncoder)

###### Visualizaci√≥n
- matplotlib.pyplot
- seaborn

Se utiliza la opcion 'display.max_columns' para ver todas columnas del fichero. Se Carga el fichero de origen en 'df_raw' y se realiza un 'head' para ver que contiene los datos.


**Carga de datos**  

Se cargan los datos de fichero que se export√≥ anteriormente con los datos limpios. El fichero se llama 'dataset_estudiantes_clean.csv'


**Gesti√≥n de Outliers**

Se realizado un Boxplot por cada variable n√∫merica del fichero manteniendo la columna 'Aprobado'. Al ser una variable binaria se decidi√≥ no tenerla en cuenta en el estudio de los outliers, porque no tiene sentido visualmente; sin embargo, en el siguiente paso es √∫til para ver si los outliers aprueban. Se calcula el n√∫mero de gr√°ficos y el n√∫mero de columnas, ajustando el tama√±o de manera din√°mica.

Al analizar los outliers no vemos que nos esten sesgando los datos de estudio, por lo que entendemos que no va a afectar a la hora de aplicar alg√∫n m√©todo de marchine learning.


**Detecci√≥n de outliers mediante el m√©todo IQR**

Se crea un diccionario para almacenar toda la informaci√≥n de forma organizada. Se calcula el √≠ndice intercuart√≠lico para visualizar los outliers. Se definen dos l√≠mites (1.5 por encima del cuartil 3 y 1.5 por debajo del cuartil 1), y los datos que quedan fuera de estos l√≠mites se consideran outliers. S√≥lo tenemos 3 variables con outliers:

*1. horas_estudio_semanal:*  
Aparecen 4 estudiantes que dedicaron m√°s horas de estudio. Al analizar las otras variables, no parece que esta informaci√≥n afecte a los datos. Hay personas que necesitan m√°s tiempo para estudiar o retener la informaci√≥n. Aunque dediques m√°s horas, no garantiza la m√°xima nota, pero s√≠ que puedes aprobar. 

*2. tasa_asistencia:*  
Se encuentran otros 4 estudiantes con la tasa de asistencia m√°s baja. No parece que sesguen los datos: 3 de ellos aprobaron y solo 1 suspendi√≥. Tambi√©n se observa que este √∫ltimo dedic√≥ solo 1 hora semanal de estudio.

*3. nota_final:*  
Aparecen outliers en ambos extremos: 2 con la nota m√°s alta y 3 con las notas m√°s bajas. Estos √∫ltimos dedicaron pocas horas de estudio comparados con los compa√±eros que aprobaron. Como mencionamos, estos outliers no afectan significativamente al an√°lisis.


**Detecci√≥n de outliers mediante el m√©todo Z-score**

Otra forma de analizar los outliers es utilizando el 'Z-score'. Se buscan los que est√°n a m√°s de 3 desviaciones est√°ndar de la media y aparecen 4 outliers: 
- 2 estudiantes dedicando 25 'horas_estudio_semanal'.
- 2 alumnos con las 'nota_final' m√°s bajas con un 30% y un 40%.

Como se dijo en caso anterior no sse van a eliminar esos registros porque no est√°n afectando a los datos de estudio.


**Regresi√≥n**

*La variable objetivo es nota_final*
Se ha creado una copia del dataFrame 'df_reg' para trabajar con ese y no modificar el 'df_clean'. Adem√°s se define la variable objetivo 'nota_final'.


**Codificaci√≥n**

El objetivo es convertir las variables categ√≥ricas en valores num√©ricos.

*1. OrdinalEncoder*
Se utiliza 'OrdinalEncoder' para las variables con orden: 'nivel_dificultad' y 'tiene_tutor'. Se convierten los valores de cada columna a n√∫meros, asegurando que 'nivel_dificultad' empiece desde 1.

*2. OneHotEncoder*
Se utiliza 'OneHotEncoder' para variables nominales sin orden: 'horario_estudio_preferido' y 'estilo_aprendizaje'. Con fit, se aprenden todas las categor√≠as y se les asigna un valor 0/1. Luego se recortan los nombres de los encabezados para que el dataframe sea legible. Se crea un dataframe 'encoded_df' con el mismo √≠ndice que 'df_reg' para combinarlo f√°cilmente. Finalmente, se eliminan las columnas originales y se a√±aden las nuevas codificadas a 'df_reg'.

Para mantener el preprocesamiento del estudio de los dos modelos (regresi√≥n y clasificaci√≥n) se realiza una copia del dataframe antes de hacer el siguiente paso.


**Escalado**


*MinMaxScaler*
Se realiza un escalado de los datos para que todas la variables se encuentren en la misma escala entre 0 y 1 menos la variable objetivo 'nota_final'


**Clasificaci√≥n**

Se realiza lo mismo que en el paso anterior pero ahora excluyendo la variable 'aprobado'


**Guardar Dfs preprocesados**

Se guarda 'df_regresion.csv' en la carpeta '../data/processed' para su posterior uso. Se hace lo mismo con 'df_clasificacion.csv'

### 4. 03_Regresi√≥n

**Importar librer√≠as**  
Importamos las librer√≠as necesarias para hacer nuestro an√°lisis:

##### Manipulaci√≥n de datos
- pandas
- numpy

##### Opcional: ver todas las columnas del DataFrame
pd.set_option('display.max_columns', None)

##### Visualizaci√≥n
- matplotlib.pyplot
- seaborn 

##### Guardado y carga de modelos
- joblib

##### Divisi√≥n de datos y validaci√≥n
- sklearn.model_selection (train_test_split)

##### Modelos de regresi√≥n:
##### Regresi√≥n lineal b√°sica
- sklearn.linear_model (LinearRegression)

##### Regresiones con regularizaci√≥n
- sklearn.linear_model (Ridge, Lasso, ElasticNet)

##### Modelo no lineal y flexible
- sklearn.ensemble (RandomForestRegressor)

##### Transformaciones y generaci√≥n de caracter√≠sticas
- sklearn.preprocessing (PolynomialFeatures)

##### M√©tricas de evaluaci√≥n
- sklearn.metrics (r2_score, mean_squared_error, mean_absolute_error)


**Carga de datos**  

Se cargan los datos preprocesados del fichero 'df_regresion.csv'

*Separaci√≥n del conjunto de datos*
Se separa la variable 'nota_final' de las variables predictoras. Luego, se divide el dataset en entrenamiento (80%) y prueba (20%) con 'train_test_split':
- Tama√±o del conjunto de entranmiento: (800, 17)
- Tama√±o del conjunto de prueba: (200, 17)


**Entrenamiento del modelo**  

Se entrena el modelo con 'LinearRegression', pasando las variables predictoras y la respuesta. Luego se predicen nuevos valores con 'predict'.


**Validaci√≥n del modelo**  

*Comparaci√≥n con Scatterplot*
Se grafica la predicci√≥n frente a los valores reales. Se a√±ade una l√≠nea diagonal de referencia; idealmente todos los puntos azules deber√≠an estar sobre ella. Se observa una ligera desigualdad.

*Comparaci√≥n de distribuciones*
Se comparan las distribuciones reales y predichas mediante histogramas. Los resultados son similares, pero se observan algunas diferencias.


**Residuos**  

Los residuos son la diferencia entre valores reales y predichos. Se visualizan en scatterplots e histogramas. Idealmente deber√≠an centrarse en 0. Se observa un pico en torno a 0 y errores menos frecuentes a mayor magnitud, lo cual es normal.


**Importancia de las caracter√≠sitcas** 

Se calcula la importancia mediante los coeficientes lineales. Destacan:
- 'aprobado': mayor coeficiente, coherente con los estudiantes aprobados que tienen 'nota_final' > 60%.
- 'horas_estudio_semanal': m√°s horas ‚Üí mayor nota.
- 'nota_anterior': estudiantes que aprobaron antes tienden a aprobar ahora.
- 'tasa_asistencia': influye en la nota final.

Se a√±ade un gr√°fico de barras para visualizar la importancia de manera clara.


**M√©tricas**

Se eval√∫a desempe√±o en entrenamiento y prueba:
- *R¬≤*: no es muy alto por lo que hay bastante variabilidad que el modelo no captura. La diferencia train y test no es muy grande, indica que no hay un sobreajuste fuerte, aunque el modelo tampoco tiene mucha capacidad predictiva.
- *MAE y RMSE*: Los errores son homog√©neos y no hay valores extremos desproporcionados.

Dado este comportamiento, se decidi√≥ entrenar un modelo m√°s potente para intentar mejorar las m√©tricas: un 'RandomForestRegressor'. Para aumentar su capacidad predictiva, se generaron interacciones lineales entre las variables originales utilizando 'PolynomialFeatures'. Esto significa que se crearon nuevas variables que representan el producto de pares de variables originales, sin elevar al cuadrado ninguna de ellas, permitiendo al modelo capturar relaciones conjuntas que no se reflejan usando solo las variables individuales.

Posteriormente, se entren√≥ el 'RandomForest' con par√°metros optimizados para reducir el sobreajuste. Esta combinaci√≥n de interacciones lineales y RandomForest optimizado permiti√≥ capturar relaciones m√°s complejas entre variables, mejorando el desempe√±o predictivo mientras se manten√≠a un equilibrio entre ajuste y generalizaci√≥n. Los resultados obtenidos fueron:

- *Train R¬≤*: Aumenta de 0.54 a 0.66, mostrando que el modelo explica m√°s varianza en el entrenamiento gracias a las interacciones y a la mayor capacidad del RandomForest.
- *Test R¬≤*: Se mantiene aproximadamente igual (0.48 ‚Üí 0.47), lo que indica que la capacidad de generalizaci√≥n no mejor√≥ significativamente; el l√≠mite parece estar dado por la informaci√≥n disponible en las features.
- *Train MAE/RMSE*: Disminuyen, lo que refleja que el modelo se ajusta mejor a los datos de entrenamiento.
- *Test MAE/RMSE*: Ligeramente mayores que el modelo lineal, reflejando un peque√±o sobreajuste.

En conclusi√≥n, el modelo mejorado es m√°s potente y flexible, pero la informaci√≥n contenida en las features actuales sigue limitando el R¬≤ en el conjunto de prueba.


**Entrenamiento final**

Se entrena el modelo final utilizando todo el conjunto de datos, de manera que aproveche toda la informaci√≥n disponible para ajustar los coeficientes. Una vez entrenado, se guarda el modelo en un archivo llamado 'modelo_regresion.pkl' usando joblib.dump. Esto permite preservar el modelo entrenado y reutilizarlo en producci√≥n sin necesidad de volver a entrenarlo, asegurando que las predicciones futuras se realicen con el mismo modelo.

Adem√°s, Se probaron varios modelos de regresi√≥n lineal con t√©cnicas de regularizaci√≥n (Ridge, Lasso y ElasticNet) para mejorar la capacidad predictiva del modelo inicial.

- Ridge: mantuvo resultados similares al modelo lineal simple, con R¬≤ de test 0.49 y errores MAE/RMSE casi iguales.
- Lasso: mostr√≥ resultados comparables, ligeramente inferiores en train, pero con R¬≤ de test 0.49, sin mejora significativa.
- ElasticNet: tuvo un desempe√±o menor tanto en entrenamiento como en test (R¬≤ de test 0.45), indicando que no capturaba mejor las relaciones de las variables.

En general, ninguna de estas t√©cnicas de regularizaci√≥n super√≥ el rendimiento del modelo lineal simple. Por ello, se decidi√≥ finalmente utilizar el RandomForestRegressor optimizado con interacciones, que mostr√≥ un mejor desempe√±o en entrenamiento (R¬≤ train 0.66) y mantuvo una generalizaci√≥n estable en test (R¬≤ test 0.47), ofreciendo un equilibrio entre ajuste y capacidad predictiva superior a los modelos lineales.


**Resultados**

El modelo lineal simple explic√≥ parte de la varianza (R¬≤ test ‚âà 0.49).
El RandomForest con interacciones mejor√≥ el ajuste en entrenamiento (R¬≤ train ‚âà 0.66), pero el R¬≤ en test se mantuvo limitado (‚âà 0.47).
Las variables m√°s influyentes fueron: 'aprobado', 'horas_estudio_semanal', 'nota_anterior' y 'tasa_asistencia'.

### 5. 04_Clasificacion

**Importar librer√≠as**  
Importamos las librer√≠as necesarias para hacer nuestro an√°lisis:

##### Manipulaci√≥n de datos
- pandas

##### Opcional: ver todas las columnas del DataFrame
pd.set_option('display.max_columns', None)

##### Visualizaci√≥n
- matplotlib.pyplot

##### Guardado y carga de modelos
- joblib

##### Divisi√≥n de datos y validaci√≥n
- sklearn.model_selection (train_test_split)

##### Modelos de regresi√≥n
- sklearn.linear_model (LogisticRegression)

##### M√©tricas de evaluaci√≥n
- sklearn.metrics (confusion_matrix, ConfusionMatrixDisplay)
- sklearn.metrics (accuracy_score, precision_score, recall_score, f1_score)


**Carga de datos**  

Se cargan los datos de fichero que se export√≥ anteriormente con el preprocesamiento hecho, el fichero se llama 'df_clasificacion.csv'

*Separaci√≥n del conjunto de datos*
Se separa la variable objetivo 'aprobado' del resto de variables predictoras.
A continuaci√≥n, se divide el dataset en entrenamiento (80%) y prueba (20%) utilizando la funci√≥n 'train_test_split'. Los tama√±os resultantes son:
- Tama√±o del conjunto de entranmiento: (800, 17)
- Tama√±o del conjunto de prueba: (200, 17)


**Entrenamiento del modelo**  

Se entrena el modelo de regresi√≥n log√≠stica usando el conjunto de entrenamiento, pasando como argumentos las variables predictoras y la variable objetivo 'aprobado'. Despu√©s, se obtienen las predicciones con 'predict. Asimismo, se utiliza 'predict_proba' para obtener las probabilidades de que cada estudiante apruebe o suspenda, lo que permite analizar la certeza de las predicciones del modelo.


**Validaci√≥n del modelo**  

Se utiliza una matriz de confusi√≥n para evaluar el rendimiento. En el conjunto de prueba de 200 estudiantes:
- El modelo acert√≥ con 192 estudiantes: 185 que aprueban y 7 que suspenden correctamente.
- Hubo 8 falsos positivos, es decir, estudiantes que suspendieron pero que el modelo predijo que aprobar√≠an.

Esta matriz permite identificar errores espec√≠ficos del modelo y analizar si existe un sesgo hacia la clase mayoritaria (aprobados).


**M√©tricas**

Se calculan las m√©tricas de desempe√±o tanto para el conjunto de entrenamiento como para el de prueba:
- *Train Accuracy*: El modelo acierta en un 92% de los casos de entrenamiento
- *Train Precission*: Cuando predice positivo, acierta en un 92%
- *Train Recall*: Detecta todos los positivos reales
- *Train F1-score*: Muy buen balance entre precisi√≥n y recall.
- *Test Accuracy*: En los datos nuevos, el modelo funciona incluso mejor con un 96%
- *Test Precission*: Alt√≠sima precisi√≥n en los positivos predichos.
- *Test Recall*: Mantiene recall, no se le escapa ning√∫n positivo real
- *Test F1-score*: ha sido de un 98%, lo que confirma el excelente equilibrio.

En conclusi√≥n, no se observa sobreajuste: el modelo generaliza bien. El hecho de que en test el rendimiento sea incluso un poco mejor puede deberse a que la muestra de prueba es m√°s ‚Äúf√°cil‚Äù de clasificar o simplemente a la variabilidad estad√≠stica (suerte en el split).

Se comprueba que la variable est√° desbalanceada, existe un 89.8% de estudiantes que aprueban frente al 10.2% que no, por lo que suelen afectar a las m√©tricas y se va a hacer que se ponderen en funci√≥n de como de representativas sea cada una de esas categor√≠as. 
- *Accuracy*: Sigue siendo alto (92% en train, 96% en test)
- *Precision*: En train es 0.93 y en test 0.96. Esto significa que, en promedio, cuando el modelo predice una clase (incluyendo las minoritarias), acierta muy bien. La ponderaci√≥n hace que las clases con m√°s ejemplos pesen m√°s en el c√°lculo.
- *Recall*: Tambi√©n muy alto (0.92 en train, 0.96 en test). Esto indica que el modelo detecta correctamente la mayor√≠a de instancias de todas las clases, incluso de la minoritaria, ya que el promedio ponderado refleja el recall global ajustado por frecuencia.
- *F1-score*: El balance entre precisi√≥n y recall es s√≥lido (0.90 en train y 0.95 en test). Al ser ponderado, este valor muestra que el modelo logra un equilibrio general en todas las clases, sin dejar que la clase mayoritaria 'tape' los errores en la minoritaria.

El modelo generaliza muy bien: las m√©tricas en test son incluso ligeramente mejores que en train porque no hay sobreajuste.
Gracias a la ponderaci√≥n, se confirma que el modelo mantiene buen rendimiento incluso con clases desbalanceadas, no solo optimizando para la clase mayoritaria.
El hecho de que train tenga un F1 un poco menor (0.90 vs 0.95 en test) probablemente se deba a variabilidad en el split (quiz√°s en train hab√≠a m√°s ejemplos complicados de la clase minoritaria).


**Importancia de las caracter√≠sitcas** 

Se mide la importancia de las caracter√≠sticas utilizando los coeficientes lineales del modelo de regresi√≥n log√≠stica.

- La variable m√°s influyente es 'nota_final', lo que tiene sentido, ya que la mayor√≠a de los estudiantes que superan el 60% de la nota final aprueban.
- Otras variables tambi√©n aportan informaci√≥n, aunque con menor peso.

Adem√°s se a√±ade tambi√©n un gr√°fico de barras para ver el resultado de manera m√°s visual.


**Entrenamiento final**

Tas entrenar el modelo de clasificaci√≥n con todo el conjunto de datos, se guard√≥ en 'modelo_clasificacion.pkl' mediante 'joblib.dump', lo que permite reutilizarlo en producci√≥n sin necesidad de volver a entrenarlo.


**Comparativa de variantes de regresi√≥n log√≠stica con regularizaci√≥n**

Se evaluaron tres variantes para mejorar la capacidad predictiva y la estabilidad:

*1. Logistic (L2 ‚Äì Ridge)*
Presenta el mejor desempe√±o global. En entrenamiento alcanza un accuracy de 0.92 y un F1 de 0.90, mientras que en prueba mejora hasta 0.96 en accuracy y 0.95 en F1. Estos valores indican que el modelo generaliza muy bien y ofrece un equilibrio adecuado entre precisi√≥n y recall.

*2. Logistic (L1 ‚Äì Lasso)*
Obtiene un rendimiento algo inferior, con accuracy de 0.89 en entrenamiento y 0.92 en prueba. El F1 en prueba se sit√∫a en 0.89, lo que refleja un comportamiento correcto pero menos robusto que Ridge. Su principal ventaja es la capacidad de selecci√≥n autom√°tica de variables, lo que puede ser √∫til en escenarios con muchas caracter√≠sticas irrelevantes.

*3. Logistic (ElasticNet)*
Muestra resultados similares a Lasso: accuracy de 0.89 en entrenamiento y 0.92 en prueba, con un F1 de 0.89. Aunque combina las propiedades de L1 y L2, en este caso no supera el rendimiento de Ridge y presenta menor precisi√≥n en entrenamiento (0.79), lo que sugiere un ajuste menos equilibrado.

En conclusi√≥n, entre las tres variantes evaluadas, la regresi√≥n log√≠stica con regularizaci√≥n L2 (Ridge) se posiciona como la mejor opci√≥n, al ofrecer el mayor rendimiento en el conjunto de prueba (Accuracy 0.96, F1 0.95) y una excelente capacidad de generalizaci√≥n.


**Resultados**

El modelo de regresi√≥n log√≠stica alcanz√≥ un rendimiento excelente.
Accuracy: 92% en train y 96% en test.
Precision / Recall / F1-score: Todos muy altos, incluso con la clase desbalanceada (89.8% aprobados vs 10.2% suspensos).
La variable m√°s influyente fue la nota_final, lo cual es coherente.

## üß† Conclusi√≥n

1. El preprocesamiento de los datos (limpieza, imputaci√≥n de nulos, escalado y codificaci√≥n) permiti√≥ obtener un dataset consistente y listo para aplicar modelos de machine learning.

2. El modelo de regresi√≥n lineal ofrece un rendimiento aceptable, pero limitado: predice con cierta precisi√≥n la nota final, aunque queda bastante varianza sin explicar. Modelos m√°s complejos como RandomForest logran mejorar el ajuste en train, pero no aportan una mejora significativa en test.

3. El modelo de regresi√≥n log√≠stica funcion√≥ de manera sobresaliente para clasificar estudiantes entre aprobados y suspensos. A pesar del desbalance de clases, el modelo generaliz√≥ muy bien, con m√©tricas muy altas en train y test.

4. Entre las variables m√°s influyentes destacan la nota anterior, las horas de estudio semanal y la asistencia, lo que resulta coherente con la realidad acad√©mica.

5. En conclusi√≥n, la clasificaci√≥n es mucho m√°s fiable que la regresi√≥n en este caso, dado que predecir si un estudiante aprueba es m√°s estable que estimar su nota exacta.
   
## ü§ù Contribuciones
Las contribuciones son bienvenidas. Si deseas mejorar el proyecto, por favor abre un pull request o una issue.

## ‚úíÔ∏è Autores

Alejandro Pedraza

@alexPedrazaG